{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d125a36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-04 17:32:45.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/azureuser/.cache/mads_datasets/gestures\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 2600/2600 [00:00<00:00, 3292.10it/s]\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 651/651 [00:00<00:00, 3323.68it/s]\n"
     ]
    }
   ],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from mltrainer.preprocessors import PaddedPreprocessor\n",
    "\n",
    "import sys \n",
    "import os\n",
    "sys.path.append(os.path.abspath('../networks'))\n",
    "sys.path.append(os.path.abspath('../dev'))\n",
    "\n",
    "preprocessor = PaddedPreprocessor()\n",
    "\n",
    "gesturesdatasetfactory = DatasetFactoryProvider.create_factory(DatasetType.GESTURES)\n",
    "streamers = gesturesdatasetfactory.create_datastreamer(batchsize=32, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]\n",
    "\n",
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc00d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltrainer import TrainerSettings, ReportTypes\n",
    "from mltrainer.metrics import Accuracy\n",
    "import torch\n",
    "\n",
    "accuracy = Accuracy()\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6c9fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "epochs: 10\n",
       "metrics: [Accuracy]\n",
       "logdir: gestures\n",
       "train_steps: 81\n",
       "valid_steps: 20\n",
       "reporttypes: [<ReportTypes.TOML: 'TOML'>, <ReportTypes.TENSORBOARD: 'TENSORBOARD'>, <ReportTypes.MLFLOW: 'MLFLOW'>]\n",
       "optimizer_kwargs: {'lr': 0.001, 'weight_decay': 1e-05}\n",
       "scheduler_kwargs: {'factor': 0.5, 'patience': 5}\n",
       "earlystop_kwargs: {'save': True, 'verbose': True, 'patience': 5}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=10, \n",
    "    metrics=[accuracy],\n",
    "    logdir=Path(\"gestures\"),\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.TOML, ReportTypes.TENSORBOARD, ReportTypes.MLFLOW],\n",
    "    scheduler_kwargs={\"factor\": 0.5, \"patience\": 5},\n",
    "    earlystop_kwargs = {\n",
    "        \"save\": False, # save every best model, and restore the best one\n",
    "        \"verbose\": True,\n",
    "        \"patience\": 5, # number of epochs with no improvement after which training will be stopped\n",
    "    }\n",
    ")\n",
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e56d257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-04 17:13:20.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to gestures/20250604-171320\u001b[0m\n",
      "\u001b[32m2025-06-04 17:13:20.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 26.60it/s]\n",
      "\u001b[32m2025-06-04 17:13:23.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 2.4774 test 2.1521 metric ['0.2281']\u001b[0m\n",
      "\u001b[32m2025-06-04 17:13:23.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (2.1521 --> 2.1521).Saving gestures/20250604-171320/checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 26.94it/s]\n",
      "\u001b[32m2025-06-04 17:13:26.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 2.0533 test 1.8739 metric ['0.3141']\u001b[0m\n",
      "\u001b[32m2025-06-04 17:13:26.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (2.1521 --> 1.8739).Saving gestures/20250604-171320/checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 26.98it/s]\n",
      "\u001b[32m2025-06-04 17:13:30.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 1.7442 test 1.3759 metric ['0.5469']\u001b[0m\n",
      "\u001b[32m2025-06-04 17:13:30.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (1.8739 --> 1.3759).Saving gestures/20250604-171320/checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 27.40it/s]\n",
      "\u001b[32m2025-06-04 17:13:33.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 1.1456 test 0.7950 metric ['0.7344']\u001b[0m\n",
      "\u001b[32m2025-06-04 17:13:33.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (1.3759 --> 0.7950).Saving gestures/20250604-171320/checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 28.65it/s]\n",
      "\u001b[32m2025-06-04 17:13:36.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.6075 test 0.4231 metric ['0.8859']\u001b[0m\n",
      "\u001b[32m2025-06-04 17:13:36.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.7950 --> 0.4231).Saving gestures/20250604-171320/checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 29.66it/s]\n",
      "\u001b[32m2025-06-04 17:13:39.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 5 train 0.3468 test 0.2020 metric ['0.9609']\u001b[0m\n",
      "\u001b[32m2025-06-04 17:13:39.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.4231 --> 0.2020).Saving gestures/20250604-171320/checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 26.71it/s]\n",
      "\u001b[32m2025-06-04 17:13:42.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 6 train 0.1652 test 0.1695 metric ['0.9594']\u001b[0m\n",
      "\u001b[32m2025-06-04 17:13:42.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.2020 --> 0.1695).Saving gestures/20250604-171320/checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 27.21it/s]\n",
      "\u001b[32m2025-06-04 17:13:45.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 7 train 0.0940 test 0.1057 metric ['0.9812']\u001b[0m\n",
      "\u001b[32m2025-06-04 17:13:45.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.1695 --> 0.1057).Saving gestures/20250604-171320/checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 26.82it/s]\n",
      "\u001b[32m2025-06-04 17:13:48.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 8 train 0.0726 test 0.1253 metric ['0.9688']\u001b[0m\n",
      "\u001b[32m2025-06-04 17:13:48.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.1057, current loss 0.1253.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 27.25it/s]\n",
      "\u001b[32m2025-06-04 17:13:51.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 9 train 0.0615 test 0.0650 metric ['0.9875']\u001b[0m\n",
      "\u001b[32m2025-06-04 17:13:51.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.1057 --> 0.0650).Saving gestures/20250604-171320/checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:31<00:00,  3.15s/it]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from mltrainer import Trainer\n",
    "from torch import optim\n",
    "\n",
    "from RNN import GRUmodel, ModelConfig\n",
    "\n",
    "modeldir = Path(\"gestures\").resolve()\n",
    "if not modeldir.exists():\n",
    "    modeldir.mkdir(parents=True)\n",
    "\n",
    "config = ModelConfig(\n",
    "    input_size=3, # vast\n",
    "    hidden_size=128,\n",
    "    num_layers=2,\n",
    "    output_size=20, # vast\n",
    "    dropout=0.2,\n",
    ")\n",
    "\n",
    "model = GRUmodel(\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optim.Adam,\n",
    "    traindataloader=trainstreamer,\n",
    "    validdataloader=validstreamer,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    ")\n",
    "\n",
    "trainer.loop()\n",
    "\n",
    "if not settings.earlystop_kwargs[\"save\"]:\n",
    "    tag = datetime.now().strftime(\"%Y%m%d-%H%M-\")\n",
    "    modelpath = modeldir / (tag + \"model.pt\")\n",
    "    torch.save(model, modelpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
