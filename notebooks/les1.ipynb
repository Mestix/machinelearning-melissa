{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "sys.path.append(os.path.abspath('../models'))\n",
    "sys.path.append(os.path.abspath('../dev'))\n",
    "\n",
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "from mltrainer import Trainer, TrainerSettings, ReportTypes, metrics\n",
    "from neural_network import NeuralNetwork\n",
    "from neural_network import DeepNeuralNetwork\n",
    "\n",
    "from helpers import get_last_accuracy_from_tensorboard\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-06 17:43:27.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/azureuser/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-05-06 17:43:27.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/azureuser/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "fashionfactory = DatasetFactoryProvider.create_factory(DatasetType.FASHION)\n",
    "preprocessor = BasePreprocessor()\n",
    "\n",
    "batchsize = 64\n",
    "\n",
    "streamers = fashionfactory.create_datastreamer(batchsize=batchsize, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]\n",
    "\n",
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()\n",
    "\n",
    "accuracy = metrics.Accuracy()\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "units = [2048, 1024, 512, 256, 128, 64, 32, 16]\n",
    "\n",
    "epochs = 5\n",
    "accuracies5 = []\n",
    "dir = \"modellogs/UNITS/EPOCH5/\"\n",
    "\n",
    "for units1 in units:\n",
    "    row = []\n",
    "    for units2 in units:\n",
    "        logdir = f\"{dir}u{units1}_u{units2}_e{epochs}\"\n",
    "\n",
    "        settings = TrainerSettings(\n",
    "            epochs=epochs,\n",
    "            metrics=[accuracy],\n",
    "            logdir=\"modellogs\",\n",
    "            train_steps=100,\n",
    "            valid_steps=100,\n",
    "            reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML]\n",
    "        )\n",
    "\n",
    "        model = NeuralNetwork(num_classes=10, units1=units1, units2=units2)\n",
    "        settings.logdir = f\"{dir}u{units1}_u{units2}_e{epochs}\"\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            settings=settings,\n",
    "            loss_fn=loss_func,\n",
    "            optimizer=optim.Adam,\n",
    "            traindataloader=trainstreamer,\n",
    "            validdataloader=validstreamer,\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "        )\n",
    "\n",
    "        trainer.loop()\n",
    "        \n",
    "        tb_subdirs = [os.path.join(logdir, d) for d in os.listdir(logdir) if os.path.isdir(os.path.join(logdir, d))]\n",
    "\n",
    "        # Zoek eerste subdir met tensorboard events\n",
    "        tb_dir = next((d for d in tb_subdirs if any(\"events.out.tfevents\" in f for f in os.listdir(d))), None)\n",
    "\n",
    "        if tb_dir:\n",
    "            last_acc = get_last_accuracy_from_tensorboard(tb_dir)\n",
    "        else:\n",
    "            last_acc = np.nan\n",
    "        \n",
    "        row.append(last_acc)\n",
    "    accuracies5.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot de heatmap\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.heatmap(\n",
    "    accuracies5,\n",
    "    annot=True,\n",
    "    fmt=\".1f\",\n",
    "    xticklabels=units,\n",
    "    yticklabels=units,\n",
    "    cmap=\"YlOrRd\",\n",
    "    cbar_kws={'label': 'Accuracy (%)'}\n",
    ")\n",
    "ax.set_xlabel(\"units2\")\n",
    "ax.set_ylabel(\"units1\")\n",
    "ax.set_title(\"Laatste Accuracy per Units-Combinatie epochs = 5\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"heatmap_epochs5\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "units = [2048, 1024, 512, 256, 128, 64, 32, 16]\n",
    "\n",
    "epochs = 10\n",
    "accuracies = []\n",
    "dir = \"modellogs/UNITS/EPOCH10/\"\n",
    "\n",
    "for units1 in units:\n",
    "    row = []\n",
    "    for units2 in units:\n",
    "        logdir = f\"{dir}u{units1}_u{units2}_e{epochs}\"\n",
    "\n",
    "        settings = TrainerSettings(\n",
    "            epochs=epochs,\n",
    "            metrics=[accuracy],\n",
    "            logdir=\"modellogs\",\n",
    "            train_steps=100,\n",
    "            valid_steps=100,\n",
    "            reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML]\n",
    "        )\n",
    "\n",
    "        model = NeuralNetwork(num_classes=10, units1=units1, units2=units2)\n",
    "        settings.logdir = f\"{dir}u{units1}_u{units2}_e{epochs}\"\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            settings=settings,\n",
    "            loss_fn=loss_func,\n",
    "            optimizer=optim.Adam,\n",
    "            traindataloader=trainstreamer,\n",
    "            validdataloader=validstreamer,\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "        )\n",
    "\n",
    "        trainer.loop()\n",
    "        \n",
    "        tb_subdirs = [os.path.join(logdir, d) for d in os.listdir(logdir) if os.path.isdir(os.path.join(logdir, d))]\n",
    "\n",
    "        # Zoek eerste subdir met tensorboard events\n",
    "        tb_dir = next((d for d in tb_subdirs if any(\"events.out.tfevents\" in f for f in os.listdir(d))), None)\n",
    "\n",
    "        if tb_dir:\n",
    "            last_acc = get_last_accuracy_from_tensorboard(tb_dir)\n",
    "        else:\n",
    "            last_acc = np.nan\n",
    "        \n",
    "        row.append(last_acc)\n",
    "    accuracies.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot de heatmap\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.heatmap(\n",
    "    accuracies,\n",
    "    annot=True,\n",
    "    fmt=\".1f\",\n",
    "    xticklabels=units,\n",
    "    yticklabels=units,\n",
    "    cmap=\"YlOrRd\",\n",
    "    cbar_kws={'label': 'Accuracy (%)'}\n",
    ")\n",
    "ax.set_xlabel(\"units2\")\n",
    "ax.set_ylabel(\"units1\")\n",
    "ax.set_title(\"Laatste Accuracy per Units-Combinatie epochs = 10\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"heatmap_epochs10\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "units = [512, 256, 128]\n",
    "epochs = 10\n",
    "results = []\n",
    "\n",
    "for units1 in units:\n",
    "    for units2 in units:\n",
    "\n",
    "        settings = TrainerSettings(\n",
    "            epochs=epochs,\n",
    "            metrics=[accuracy],\n",
    "            logdir=\"modellogs\",\n",
    "            train_steps=100,\n",
    "            valid_steps=100,\n",
    "            reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML]\n",
    "        )\n",
    "\n",
    "        model = NeuralNetwork (num_classes=10, units1=units1, units2=units2)\n",
    "        settings.logdir = f\"modellogs/SGD/u{units1}_u{units2}_e{epochs}\"\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            settings=settings,\n",
    "            loss_fn=loss_func,\n",
    "            optimizer=optim.SGD,\n",
    "            traindataloader=trainstreamer,\n",
    "            validdataloader=validstreamer,\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "        )\n",
    "\n",
    "        trainer.loop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "units1 = 512\n",
    "units2 = 256\n",
    "units3 = 128\n",
    "epochs = 20\n",
    "\n",
    "settings = TrainerSettings(\n",
    "            epochs=epochs,\n",
    "            metrics=[accuracy],\n",
    "            logdir=\"modellogs\",\n",
    "            train_steps=100,\n",
    "            valid_steps=100,\n",
    "            reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML]\n",
    "        )\n",
    "\n",
    "model = DeepNeuralNetwork (num_classes=10, units1=units1, units2=units2, units3 = units3)\n",
    "settings.logdir = f\"modellogs/DEEP/u{units1}_u{units2}_u{units3}_e{epochs}\"\n",
    "        \n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_func,\n",
    "    optimizer=optim.Adam,\n",
    "    traindataloader=trainstreamer,\n",
    "    validdataloader=validstreamer,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    ")\n",
    "\n",
    "trainer.loop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "084c3c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-06 17:43:32.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/azureuser/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-05-06 17:43:32.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/azureuser/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "batchsize = 64\n",
    "\n",
    "streamers = fashionfactory.create_datastreamer(batchsize=batchsize, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]\n",
    "\n",
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()\n",
    "\n",
    "accuracy = metrics.Accuracy()\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e749ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-06 17:43:35.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/DEF/u1024_u512_e10/20250506-174335\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-06 17:43:36.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 102.72it/s]\n",
      "\u001b[32m2025-05-06 17:43:37.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 0 train 0.8524 test 0.6396 metric ['0.7736']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 99.41it/s]\n",
      "\u001b[32m2025-05-06 17:43:39.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 2 train 0.5516 test 0.5316 metric ['0.8091']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 100.53it/s]\n",
      "\u001b[32m2025-05-06 17:43:40.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 4 train 0.4973 test 0.4724 metric ['0.8286']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 102.02it/s]\n",
      "\u001b[32m2025-05-06 17:43:41.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 6 train 0.4805 test 0.4657 metric ['0.8291']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 104.73it/s]\n",
      "\u001b[32m2025-05-06 17:43:43.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 8 train 0.4449 test 0.4499 metric ['0.8402']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 103.35it/s]\n",
      "\u001b[32m2025-05-06 17:43:44.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 10 train 0.4223 test 0.4302 metric ['0.8411']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 97.16it/s]\n",
      "\u001b[32m2025-05-06 17:43:45.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 12 train 0.4220 test 0.4686 metric ['0.8300']\u001b[0m\n",
      "\u001b[32m2025-05-06 17:43:45.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4302, current loss 0.4686.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 92.14it/s]\n",
      "\u001b[32m2025-05-06 17:43:47.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 14 train 0.4126 test 0.4412 metric ['0.8431']\u001b[0m\n",
      "\u001b[32m2025-05-06 17:43:47.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4302, current loss 0.4412.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 76.67it/s]\n",
      "\u001b[32m2025-05-06 17:43:49.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 16 train 0.4026 test 0.4464 metric ['0.8378']\u001b[0m\n",
      "\u001b[32m2025-05-06 17:43:49.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4302, current loss 0.4464.Counter 3/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 92.22it/s]\n",
      "\u001b[32m2025-05-06 17:43:50.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 18 train 0.3714 test 0.3966 metric ['0.8578']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:13<00:00,  1.39s/it]\n"
     ]
    }
   ],
   "source": [
    "units = [1024, 512]\n",
    "epochs = 10\n",
    "results = []\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=epochs,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"modellogs\",\n",
    "    train_steps=100,\n",
    "    valid_steps=100,\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML],\n",
    "    optimizer_kwargs={\"lr\": 0.0005}\n",
    ")\n",
    "\n",
    "model = NeuralNetwork (num_classes=10, units1=units[0], units2=units[1])\n",
    "settings.logdir = f\"modellogs/DEF/u{units[0]}_u{units[1]}_e{epochs}\"\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_func,\n",
    "    optimizer=optim.Adam,\n",
    "    traindataloader=trainstreamer,\n",
    "    validdataloader=validstreamer,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    ")\n",
    "\n",
    "trainer.loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
