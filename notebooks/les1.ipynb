{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "070d13c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "sys.path.append(os.path.abspath('../models'))\n",
    "\n",
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "from mltrainer import Trainer, TrainerSettings, ReportTypes, metrics\n",
    "from neural_network import NeuralNetwork\n",
    "from neural_network import DeepNeuralNetwork\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a82cc6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-02 12:15:32.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/azureuser/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-05-02 12:15:32.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/azureuser/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "fashionfactory = DatasetFactoryProvider.create_factory(DatasetType.FASHION)\n",
    "preprocessor = BasePreprocessor()\n",
    "\n",
    "batchsize = 64\n",
    "\n",
    "streamers = fashionfactory.create_datastreamer(batchsize=batchsize, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]\n",
    "\n",
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()\n",
    "\n",
    "accuracy = metrics.Accuracy()\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7864e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-02 11:35:21.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/BATCHTEST/u512_u512_e20_b64/20250502-113521\u001b[0m\n",
      "\u001b[32m2025-05-02 11:35:21.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 186.68it/s]\n",
      "\u001b[32m2025-05-02 11:35:22.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 0 train 0.8585 test 0.6283 metric ['0.7692']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 182.53it/s]\n",
      "\u001b[32m2025-05-02 11:35:23.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 2 train 0.5384 test 0.5215 metric ['0.8153']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 188.49it/s]\n",
      "\u001b[32m2025-05-02 11:35:24.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 4 train 0.5012 test 0.4800 metric ['0.8305']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 174.63it/s]\n",
      "\u001b[32m2025-05-02 11:35:24.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 6 train 0.4464 test 0.4506 metric ['0.8408']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 192.33it/s]\n",
      " 20%|\u001b[38;2;30;71;6m██        \u001b[0m| 4/20 [00:03<00:15,  1.02it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     15\u001b[39m settings.logdir = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodellogs/BATCHTEST/u\u001b[39m\u001b[38;5;132;01m{\u001b[39;00munits1\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_u\u001b[39m\u001b[38;5;132;01m{\u001b[39;00munits2\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_e\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_b\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatchsize\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m trainer = Trainer(\n\u001b[32m     18\u001b[39m     model=model,\n\u001b[32m     19\u001b[39m     settings=settings,\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     scheduler=optim.lr_scheduler.ReduceLROnPlateau\n\u001b[32m     25\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/machinelearning-melissa/.venv/lib/python3.11/site-packages/mltrainer/trainer.py:96\u001b[39m, in \u001b[36mTrainer.loop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28mself\u001b[39m.last_epoch = epoch\n\u001b[32m     95\u001b[39m train_loss = \u001b[38;5;28mself\u001b[39m.trainbatches()\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m metric_dict, test_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevalbatches\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28mself\u001b[39m.report(epoch, train_loss, test_loss, metric_dict)\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.early_stopping:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/machinelearning-melissa/.venv/lib/python3.11/site-packages/mltrainer/trainer.py:142\u001b[39m, in \u001b[36mTrainer.evalbatches\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():  \u001b[38;5;66;03m# Prevent gradient computation during evaluation\u001b[39;00m\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(valid_steps):\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m         x, y = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m.validdataloader))\n\u001b[32m    143\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device:\n\u001b[32m    144\u001b[39m             x, y = x.to(\u001b[38;5;28mself\u001b[39m.device), y.to(\u001b[38;5;28mself\u001b[39m.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/machinelearning-melissa/.venv/lib/python3.11/site-packages/mads_datasets/base.py:207\u001b[39m, in \u001b[36mBaseDatastreamer.stream\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.index > (\u001b[38;5;28mself\u001b[39m.size - \u001b[38;5;28mself\u001b[39m.batchsize):\n\u001b[32m    206\u001b[39m     \u001b[38;5;28mself\u001b[39m.reset_index()\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatchloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m X, Y = \u001b[38;5;28mself\u001b[39m.preprocessor(batch)  \u001b[38;5;66;03m# noqa N806\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m X, Y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/machinelearning-melissa/.venv/lib/python3.11/site-packages/mads_datasets/base.py:198\u001b[39m, in \u001b[36mBaseDatastreamer.batchloop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    196\u001b[39m batch = []\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.batchsize):\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     x, y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    199\u001b[39m     batch.append((x, y))\n\u001b[32m    200\u001b[39m     \u001b[38;5;28mself\u001b[39m.index += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/machinelearning-melissa/.venv/lib/python3.11/site-packages/mads_datasets/datasets/torchdatasets.py:80\u001b[39m, in \u001b[36mMNISTDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# scale to [0, 1] and cast to torch.float32\u001b[39;00m\n\u001b[32m     79\u001b[39m image = image / \u001b[32m255.0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m image = \u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     81\u001b[39m label = \u001b[38;5;28mself\u001b[39m.labels[idx].type(torch.uint8)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m image, label\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "units1, units2 = 512, 512\n",
    "epochs = 20\n",
    "results = []\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=epochs,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"modellogs\",\n",
    "    train_steps=100,\n",
    "    valid_steps=100,\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML]\n",
    ")\n",
    "\n",
    "model = NeuralNetwork (num_classes=10, units1=units1, units2=units2)\n",
    "settings.logdir = f\"modellogs/BATCHTEST/u{units1}_u{units2}_e{epochs}_b{batchsize}\"\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_func,\n",
    "    optimizer=optim.Adam,\n",
    "    traindataloader=trainstreamer,\n",
    "    validdataloader=validstreamer,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    ")\n",
    "\n",
    "trainer.loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a35e4a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-02 12:05:08.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/UNITS/u128_u128_e10_b64/20250502-120508\u001b[0m\n",
      "\u001b[32m2025-05-02 12:05:08.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 292.42it/s]\n",
      "\u001b[32m2025-05-02 12:05:08.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 0 train 1.0343 test 0.6744 metric ['0.7517']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 296.72it/s]\n",
      "\u001b[32m2025-05-02 12:05:09.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 2 train 0.6143 test 0.5887 metric ['0.7792']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 293.03it/s]\n",
      "\u001b[32m2025-05-02 12:05:09.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 4 train 0.5485 test 0.5441 metric ['0.8102']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 301.92it/s]\n",
      "\u001b[32m2025-05-02 12:05:10.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 6 train 0.5013 test 0.5375 metric ['0.8070']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 295.27it/s]\n",
      "\u001b[32m2025-05-02 12:05:10.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 8 train 0.4823 test 0.5132 metric ['0.8206']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 293.60it/s]\n",
      "\u001b[32m2025-05-02 12:05:11.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 10 train 0.4724 test 0.4545 metric ['0.8384']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 285.91it/s]\n",
      "\u001b[32m2025-05-02 12:05:12.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 12 train 0.4574 test 0.4591 metric ['0.8344']\u001b[0m\n",
      "\u001b[32m2025-05-02 12:05:12.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4545, current loss 0.4591.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 298.49it/s]\n",
      "\u001b[32m2025-05-02 12:05:12.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 14 train 0.4126 test 0.4514 metric ['0.8398']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 286.96it/s]\n",
      "\u001b[32m2025-05-02 12:05:13.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 16 train 0.4292 test 0.4475 metric ['0.8375']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 297.03it/s]\n",
      "\u001b[32m2025-05-02 12:05:13.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 18 train 0.4112 test 0.4361 metric ['0.8445']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:05<00:00,  1.76it/s]\n"
     ]
    }
   ],
   "source": [
    "units1, units2 = 128, 128\n",
    "epochs = 10\n",
    "results = []\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=epochs,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"modellogs\",\n",
    "    train_steps=100,\n",
    "    valid_steps=100,\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML]\n",
    ")\n",
    "\n",
    "model = NeuralNetwork (num_classes=10, units1=units1, units2=units2)\n",
    "settings.logdir = f\"modellogs/UNITS/u{units1}_u{units2}_e{epochs}_b{batchsize}\"\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_func,\n",
    "    optimizer=optim.Adam,\n",
    "    traindataloader=trainstreamer,\n",
    "    validdataloader=validstreamer,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    ")\n",
    "\n",
    "trainer.loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "57bfa840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-02 12:07:24.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/EPOCHS/u256_u64_e20_b64/20250502-120724\u001b[0m\n",
      "\u001b[32m2025-05-02 12:07:24.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 270.25it/s]\n",
      "\u001b[32m2025-05-02 12:07:25.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 0 train 0.9935 test 0.6735 metric ['0.7520']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 271.45it/s]\n",
      "\u001b[32m2025-05-02 12:07:25.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 2 train 0.6043 test 0.5997 metric ['0.7825']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 260.45it/s]\n",
      "\u001b[32m2025-05-02 12:07:26.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 4 train 0.5061 test 0.5495 metric ['0.7973']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 272.14it/s]\n",
      "\u001b[32m2025-05-02 12:07:27.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 6 train 0.5206 test 0.4899 metric ['0.8227']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 267.31it/s]\n",
      "\u001b[32m2025-05-02 12:07:27.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 8 train 0.4610 test 0.4857 metric ['0.8278']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 260.53it/s]\n",
      "\u001b[32m2025-05-02 12:07:28.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 10 train 0.4426 test 0.4574 metric ['0.8383']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 262.17it/s]\n",
      "\u001b[32m2025-05-02 12:07:28.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 12 train 0.4231 test 0.5028 metric ['0.8191']\u001b[0m\n",
      "\u001b[32m2025-05-02 12:07:28.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4574, current loss 0.5028.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 271.52it/s]\n",
      "\u001b[32m2025-05-02 12:07:29.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 14 train 0.4206 test 0.4508 metric ['0.8386']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 270.53it/s]\n",
      "\u001b[32m2025-05-02 12:07:30.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 16 train 0.4151 test 0.4289 metric ['0.8477']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 267.35it/s]\n",
      "\u001b[32m2025-05-02 12:07:30.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 18 train 0.4114 test 0.4606 metric ['0.8272']\u001b[0m\n",
      "\u001b[32m2025-05-02 12:07:30.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4289, current loss 0.4606.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 271.92it/s]\n",
      "\u001b[32m2025-05-02 12:07:31.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 20 train 0.4022 test 0.4318 metric ['0.8481']\u001b[0m\n",
      "\u001b[32m2025-05-02 12:07:31.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4289, current loss 0.4318.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 262.86it/s]\n",
      "\u001b[32m2025-05-02 12:07:31.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 22 train 0.4061 test 0.3999 metric ['0.8567']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 258.08it/s]\n",
      "\u001b[32m2025-05-02 12:07:32.516\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 24 train 0.3902 test 0.4108 metric ['0.8506']\u001b[0m\n",
      "\u001b[32m2025-05-02 12:07:32.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.3999, current loss 0.4108.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 243.39it/s]\n",
      "\u001b[32m2025-05-02 12:07:33.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 26 train 0.3787 test 0.4330 metric ['0.8470']\u001b[0m\n",
      "\u001b[32m2025-05-02 12:07:33.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.3999, current loss 0.4330.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 246.54it/s]\n",
      "\u001b[32m2025-05-02 12:07:33.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 28 train 0.4016 test 0.4118 metric ['0.8527']\u001b[0m\n",
      "\u001b[32m2025-05-02 12:07:33.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.3999, current loss 0.4118.Counter 3/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 229.43it/s]\n",
      "\u001b[32m2025-05-02 12:07:34.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 30 train 0.3608 test 0.3973 metric ['0.8538']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 214.56it/s]\n",
      "\u001b[32m2025-05-02 12:07:35.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 32 train 0.3637 test 0.4033 metric ['0.8528']\u001b[0m\n",
      "\u001b[32m2025-05-02 12:07:35.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.3973, current loss 0.4033.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 219.91it/s]\n",
      "\u001b[32m2025-05-02 12:07:36.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 34 train 0.3592 test 0.3913 metric ['0.8644']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 213.75it/s]\n",
      "\u001b[32m2025-05-02 12:07:36.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 36 train 0.3500 test 0.3989 metric ['0.8577']\u001b[0m\n",
      "\u001b[32m2025-05-02 12:07:36.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.3913, current loss 0.3989.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 218.40it/s]\n",
      "\u001b[32m2025-05-02 12:07:37.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 38 train 0.3470 test 0.3981 metric ['0.8534']\u001b[0m\n",
      "\u001b[32m2025-05-02 12:07:37.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.3913, current loss 0.3981.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 20/20 [00:12<00:00,  1.54it/s]\n"
     ]
    }
   ],
   "source": [
    "units1, units2 = 256, 64\n",
    "epochs = 20\n",
    "results = []\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=epochs,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"modellogs\",\n",
    "    train_steps=100,\n",
    "    valid_steps=100,\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML]\n",
    ")\n",
    "\n",
    "model = NeuralNetwork (num_classes=10, units1=units1, units2=units2)\n",
    "settings.logdir = f\"modellogs/EPOCHS/u{units1}_u{units2}_e{epochs}_b{batchsize}\"\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_func,\n",
    "    optimizer=optim.Adam,\n",
    "    traindataloader=trainstreamer,\n",
    "    validdataloader=validstreamer,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    ")\n",
    "\n",
    "trainer.loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff9853f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-02 10:53:05.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/ADAM/u512_u512_e10/20250502-105305\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:05.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 132.13it/s]\n",
      "\u001b[32m2025-05-02 10:53:06.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 0 train 0.8427 test 0.5873 metric ['0.7895']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 118.80it/s]\n",
      "\u001b[32m2025-05-02 10:53:07.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 2 train 0.5502 test 0.5200 metric ['0.8197']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 117.81it/s]\n",
      "\u001b[32m2025-05-02 10:53:08.401\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 4 train 0.4891 test 0.5125 metric ['0.8222']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 127.84it/s]\n",
      "\u001b[32m2025-05-02 10:53:09.472\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 6 train 0.4709 test 0.4689 metric ['0.8283']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 129.27it/s]\n",
      "\u001b[32m2025-05-02 10:53:10.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 8 train 0.4352 test 0.4601 metric ['0.8402']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 126.49it/s]\n",
      "\u001b[32m2025-05-02 10:53:11.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 10 train 0.4177 test 0.4173 metric ['0.8497']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 111.14it/s]\n",
      "\u001b[32m2025-05-02 10:53:12.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 12 train 0.4001 test 0.4139 metric ['0.8486']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 121.02it/s]\n",
      "\u001b[32m2025-05-02 10:53:13.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 14 train 0.4018 test 0.4588 metric ['0.8350']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:13.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4139, current loss 0.4588.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 124.28it/s]\n",
      "\u001b[32m2025-05-02 10:53:15.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 16 train 0.4051 test 0.4220 metric ['0.8439']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:15.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4139, current loss 0.4220.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 126.94it/s]\n",
      "\u001b[32m2025-05-02 10:53:16.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 18 train 0.3828 test 0.3949 metric ['0.8548']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:11<00:00,  1.10s/it]\n",
      "\u001b[32m2025-05-02 10:53:16.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/ADAM/u512_u256_e10/20250502-105316\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:16.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 185.53it/s]\n",
      "\u001b[32m2025-05-02 10:53:16.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 0 train 0.8908 test 0.6341 metric ['0.7625']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 171.07it/s]\n",
      "\u001b[32m2025-05-02 10:53:17.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 2 train 0.5678 test 0.5714 metric ['0.7905']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 175.94it/s]\n",
      "\u001b[32m2025-05-02 10:53:18.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 4 train 0.4872 test 0.5211 metric ['0.8100']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 178.90it/s]\n",
      "\u001b[32m2025-05-02 10:53:19.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 6 train 0.4786 test 0.5163 metric ['0.8191']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 187.63it/s]\n",
      "\u001b[32m2025-05-02 10:53:20.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 8 train 0.4434 test 0.4441 metric ['0.8377']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 177.18it/s]\n",
      "\u001b[32m2025-05-02 10:53:21.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 10 train 0.4172 test 0.4519 metric ['0.8355']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:21.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4441, current loss 0.4519.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 167.33it/s]\n",
      "\u001b[32m2025-05-02 10:53:22.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 12 train 0.4046 test 0.4239 metric ['0.8448']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 179.02it/s]\n",
      "\u001b[32m2025-05-02 10:53:22.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 14 train 0.4198 test 0.4138 metric ['0.8489']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 186.76it/s]\n",
      "\u001b[32m2025-05-02 10:53:23.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 16 train 0.3861 test 0.4506 metric ['0.8314']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:23.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4138, current loss 0.4506.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 184.80it/s]\n",
      "\u001b[32m2025-05-02 10:53:24.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 18 train 0.3960 test 0.4390 metric ['0.8408']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:24.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4138, current loss 0.4390.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:08<00:00,  1.19it/s]\n",
      "\u001b[32m2025-05-02 10:53:24.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/ADAM/u512_u128_e10/20250502-105324\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:24.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 207.04it/s]\n",
      "\u001b[32m2025-05-02 10:53:25.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 0 train 0.9370 test 0.6509 metric ['0.7608']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 202.17it/s]\n",
      "\u001b[32m2025-05-02 10:53:26.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 2 train 0.5618 test 0.5474 metric ['0.7980']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 208.42it/s]\n",
      "\u001b[32m2025-05-02 10:53:26.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 4 train 0.5056 test 0.5164 metric ['0.8178']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 212.53it/s]\n",
      "\u001b[32m2025-05-02 10:53:27.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 6 train 0.4708 test 0.5172 metric ['0.8120']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:27.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.5164, current loss 0.5172.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 213.33it/s]\n",
      "\u001b[32m2025-05-02 10:53:28.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 8 train 0.4398 test 0.4417 metric ['0.8433']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 214.72it/s]\n",
      "\u001b[32m2025-05-02 10:53:28.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 10 train 0.4235 test 0.4283 metric ['0.8441']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 216.94it/s]\n",
      "\u001b[32m2025-05-02 10:53:29.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 12 train 0.4332 test 0.5062 metric ['0.8175']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:29.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4283, current loss 0.5062.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 215.27it/s]\n",
      "\u001b[32m2025-05-02 10:53:30.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 14 train 0.4128 test 0.4366 metric ['0.8436']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:30.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4283, current loss 0.4366.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 211.90it/s]\n",
      "\u001b[32m2025-05-02 10:53:31.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 16 train 0.4056 test 0.3937 metric ['0.8595']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 218.55it/s]\n",
      "\u001b[32m2025-05-02 10:53:31.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 18 train 0.3925 test 0.4121 metric ['0.8511']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:31.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.3937, current loss 0.4121.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:07<00:00,  1.36it/s]\n",
      "\u001b[32m2025-05-02 10:53:31.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/ADAM/u256_u512_e10/20250502-105331\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:31.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 230.04it/s]\n",
      "\u001b[32m2025-05-02 10:53:32.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 0 train 0.9183 test 0.6367 metric ['0.7638']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 232.35it/s]\n",
      "\u001b[32m2025-05-02 10:53:33.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 2 train 0.5801 test 0.5357 metric ['0.8113']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 236.32it/s]\n",
      "\u001b[32m2025-05-02 10:53:33.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 4 train 0.4838 test 0.4823 metric ['0.8286']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 136.04it/s]\n",
      "\u001b[32m2025-05-02 10:53:34.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 6 train 0.4796 test 0.4714 metric ['0.8292']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 205.04it/s]\n",
      "\u001b[32m2025-05-02 10:53:35.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 8 train 0.4335 test 0.4580 metric ['0.8337']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 192.57it/s]\n",
      "\u001b[32m2025-05-02 10:53:36.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 10 train 0.4180 test 0.4756 metric ['0.8292']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:36.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4580, current loss 0.4756.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 237.67it/s]\n",
      "\u001b[32m2025-05-02 10:53:37.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 12 train 0.4231 test 0.4308 metric ['0.8436']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 237.69it/s]\n",
      "\u001b[32m2025-05-02 10:53:37.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 14 train 0.3950 test 0.4192 metric ['0.8484']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 230.16it/s]\n",
      "\u001b[32m2025-05-02 10:53:38.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 16 train 0.4118 test 0.4310 metric ['0.8413']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:38.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4192, current loss 0.4310.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 225.43it/s]\n",
      "\u001b[32m2025-05-02 10:53:39.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 18 train 0.4032 test 0.4659 metric ['0.8300']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:39.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4192, current loss 0.4659.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:07<00:00,  1.34it/s]\n",
      "\u001b[32m2025-05-02 10:53:39.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/ADAM/u256_u256_e10/20250502-105339\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:39.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 252.41it/s]\n",
      "\u001b[32m2025-05-02 10:53:39.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 0 train 0.9025 test 0.6667 metric ['0.7664']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 243.49it/s]\n",
      "\u001b[32m2025-05-02 10:53:40.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 2 train 0.5610 test 0.5550 metric ['0.8056']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 257.91it/s]\n",
      "\u001b[32m2025-05-02 10:53:41.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 4 train 0.5076 test 0.5380 metric ['0.8055']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 263.43it/s]\n",
      "\u001b[32m2025-05-02 10:53:41.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 6 train 0.4781 test 0.4697 metric ['0.8370']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 263.63it/s]\n",
      "\u001b[32m2025-05-02 10:53:42.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 8 train 0.4534 test 0.4543 metric ['0.8420']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 252.33it/s]\n",
      "\u001b[32m2025-05-02 10:53:43.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 10 train 0.4491 test 0.4473 metric ['0.8416']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 261.87it/s]\n",
      "\u001b[32m2025-05-02 10:53:43.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 12 train 0.4222 test 0.4417 metric ['0.8419']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 259.79it/s]\n",
      "\u001b[32m2025-05-02 10:53:44.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 14 train 0.4171 test 0.4331 metric ['0.8397']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 255.87it/s]\n",
      "\u001b[32m2025-05-02 10:53:44.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 16 train 0.3874 test 0.4427 metric ['0.8398']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:44.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4331, current loss 0.4427.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 255.61it/s]\n",
      "\u001b[32m2025-05-02 10:53:45.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 18 train 0.4203 test 0.4584 metric ['0.8300']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:45.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4331, current loss 0.4584.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:06<00:00,  1.59it/s]\n",
      "\u001b[32m2025-05-02 10:53:45.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/ADAM/u256_u128_e10/20250502-105345\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:45.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 263.69it/s]\n",
      "\u001b[32m2025-05-02 10:53:46.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 0 train 0.9866 test 0.6405 metric ['0.7648']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 269.25it/s]\n",
      "\u001b[32m2025-05-02 10:53:46.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 2 train 0.5887 test 0.5766 metric ['0.7872']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 261.28it/s]\n",
      "\u001b[32m2025-05-02 10:53:47.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 4 train 0.5254 test 0.5193 metric ['0.8178']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 245.64it/s]\n",
      "\u001b[32m2025-05-02 10:53:48.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 6 train 0.4899 test 0.4949 metric ['0.8233']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 251.21it/s]\n",
      "\u001b[32m2025-05-02 10:53:48.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 8 train 0.4627 test 0.4674 metric ['0.8328']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 235.44it/s]\n",
      "\u001b[32m2025-05-02 10:53:49.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 10 train 0.4455 test 0.4791 metric ['0.8273']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:49.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4674, current loss 0.4791.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 248.17it/s]\n",
      "\u001b[32m2025-05-02 10:53:50.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 12 train 0.4386 test 0.4834 metric ['0.8200']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:50.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4674, current loss 0.4834.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 167.94it/s]\n",
      "\u001b[32m2025-05-02 10:53:50.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 14 train 0.4162 test 0.4262 metric ['0.8462']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 201.26it/s]\n",
      "\u001b[32m2025-05-02 10:53:51.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 16 train 0.4092 test 0.4366 metric ['0.8448']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:51.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4262, current loss 0.4366.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 151.66it/s]\n",
      "\u001b[32m2025-05-02 10:53:52.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 18 train 0.4083 test 0.4492 metric ['0.8350']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:52.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4262, current loss 0.4492.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:07<00:00,  1.41it/s]\n",
      "\u001b[32m2025-05-02 10:53:52.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/ADAM/u128_u512_e10/20250502-105352\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:52.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 263.53it/s]\n",
      "\u001b[32m2025-05-02 10:53:53.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 0 train 0.9208 test 0.6591 metric ['0.7481']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 249.83it/s]\n",
      "\u001b[32m2025-05-02 10:53:53.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 2 train 0.5859 test 0.5518 metric ['0.8044']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 251.38it/s]\n",
      "\u001b[32m2025-05-02 10:53:54.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 4 train 0.5157 test 0.4946 metric ['0.8245']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 261.99it/s]\n",
      "\u001b[32m2025-05-02 10:53:55.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 6 train 0.4610 test 0.4945 metric ['0.8242']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 251.02it/s]\n",
      "\u001b[32m2025-05-02 10:53:55.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 8 train 0.4554 test 0.4619 metric ['0.8330']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 266.19it/s]\n",
      "\u001b[32m2025-05-02 10:53:56.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 10 train 0.4478 test 0.4912 metric ['0.8234']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:56.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4619, current loss 0.4912.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 268.30it/s]\n",
      "\u001b[32m2025-05-02 10:53:57.091\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 12 train 0.4319 test 0.4392 metric ['0.8423']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 265.22it/s]\n",
      "\u001b[32m2025-05-02 10:53:57.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 14 train 0.4138 test 0.4522 metric ['0.8336']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:57.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4392, current loss 0.4522.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 261.40it/s]\n",
      "\u001b[32m2025-05-02 10:53:58.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 16 train 0.4106 test 0.4240 metric ['0.8505']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 265.95it/s]\n",
      "\u001b[32m2025-05-02 10:53:58.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 18 train 0.3949 test 0.4362 metric ['0.8431']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:58.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4240, current loss 0.4362.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:06<00:00,  1.60it/s]\n",
      "\u001b[32m2025-05-02 10:53:58.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/ADAM/u128_u256_e10/20250502-105358\u001b[0m\n",
      "\u001b[32m2025-05-02 10:53:58.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 271.52it/s]\n",
      "\u001b[32m2025-05-02 10:53:59.552\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 0 train 1.0013 test 0.6618 metric ['0.7622']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 275.52it/s]\n",
      "\u001b[32m2025-05-02 10:54:00.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 2 train 0.6111 test 0.5480 metric ['0.8064']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 266.26it/s]\n",
      "\u001b[32m2025-05-02 10:54:00.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 4 train 0.5089 test 0.5490 metric ['0.8050']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:54:00.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.5480, current loss 0.5490.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 256.87it/s]\n",
      "\u001b[32m2025-05-02 10:54:01.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 6 train 0.4980 test 0.4974 metric ['0.8223']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 277.48it/s]\n",
      "\u001b[32m2025-05-02 10:54:01.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 8 train 0.4660 test 0.4872 metric ['0.8284']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 268.61it/s]\n",
      "\u001b[32m2025-05-02 10:54:02.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 10 train 0.4451 test 0.4861 metric ['0.8230']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 266.57it/s]\n",
      "\u001b[32m2025-05-02 10:54:03.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 12 train 0.4589 test 0.4606 metric ['0.8337']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 273.33it/s]\n",
      "\u001b[32m2025-05-02 10:54:03.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 14 train 0.4274 test 0.4686 metric ['0.8334']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:54:03.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4606, current loss 0.4686.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 265.57it/s]\n",
      "\u001b[32m2025-05-02 10:54:04.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 16 train 0.4079 test 0.4150 metric ['0.8534']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 266.31it/s]\n",
      "\u001b[32m2025-05-02 10:54:05.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 18 train 0.4118 test 0.4402 metric ['0.8467']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:54:05.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4150, current loss 0.4402.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:06<00:00,  1.64it/s]\n",
      "\u001b[32m2025-05-02 10:54:05.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/ADAM/u128_u128_e10/20250502-105405\u001b[0m\n",
      "\u001b[32m2025-05-02 10:54:05.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 281.47it/s]\n",
      "\u001b[32m2025-05-02 10:54:05.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 0 train 1.0431 test 0.6834 metric ['0.7497']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 267.68it/s]\n",
      "\u001b[32m2025-05-02 10:54:06.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 2 train 0.5919 test 0.5594 metric ['0.7950']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 282.13it/s]\n",
      "\u001b[32m2025-05-02 10:54:06.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 4 train 0.5296 test 0.5413 metric ['0.8034']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 268.83it/s]\n",
      "\u001b[32m2025-05-02 10:54:07.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 6 train 0.5185 test 0.5412 metric ['0.8064']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 264.90it/s]\n",
      "\u001b[32m2025-05-02 10:54:08.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 8 train 0.4854 test 0.5680 metric ['0.7950']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:54:08.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.5412, current loss 0.5680.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 220.28it/s]\n",
      "\u001b[32m2025-05-02 10:54:08.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 10 train 0.4855 test 0.4664 metric ['0.8334']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 260.18it/s]\n",
      "\u001b[32m2025-05-02 10:54:09.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 12 train 0.4445 test 0.4286 metric ['0.8486']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 247.90it/s]\n",
      "\u001b[32m2025-05-02 10:54:10.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 14 train 0.4153 test 0.4887 metric ['0.8203']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:54:10.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4286, current loss 0.4887.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 261.03it/s]\n",
      "\u001b[32m2025-05-02 10:54:10.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 16 train 0.4226 test 0.4475 metric ['0.8375']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:54:10.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4286, current loss 0.4475.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 261.91it/s]\n",
      "\u001b[32m2025-05-02 10:54:11.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 18 train 0.4195 test 0.4354 metric ['0.8466']\u001b[0m\n",
      "\u001b[32m2025-05-02 10:54:11.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4286, current loss 0.4354.Counter 3/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:06<00:00,  1.57it/s]\n"
     ]
    }
   ],
   "source": [
    "units = [512, 512, 128]\n",
    "epochs = 10\n",
    "results = []\n",
    "\n",
    "for units1 in units:\n",
    "    for units2 in units:\n",
    "\n",
    "        settings = TrainerSettings(\n",
    "            epochs=epochs,\n",
    "            metrics=[accuracy],\n",
    "            logdir=\"modellogs\",\n",
    "            train_steps=100,\n",
    "            valid_steps=100,\n",
    "            reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML]\n",
    "        )\n",
    "\n",
    "        model = NeuralNetwork (num_classes=10, units1=units1, units2=units2)\n",
    "        settings.logdir = f\"modellogs/ADAM/u{units1}_u{units2}_e{epochs}\"\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            settings=settings,\n",
    "            loss_fn=loss_func,\n",
    "            optimizer=optim.Adam,\n",
    "            traindataloader=trainstreamer,\n",
    "            validdataloader=validstreamer,\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "        )\n",
    "\n",
    "        trainer.loop()\n",
    "\n",
    "        results.append({\n",
    "            \"units1\": units1,\n",
    "            \"units2\": units2,\n",
    "            \"run_dir\": settings.logdir,\n",
    "            \"epoch\": epochs,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83480eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-02 10:46:33.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/SGD/u512_u512_e10/20250502-104633\u001b[0m\n",
      "\u001b[32m2025-05-02 10:46:33.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 231.57it/s]\n",
      "\u001b[32m2025-05-02 10:46:34.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 0 train 2.2966 test 2.2905 metric ['0.1630']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 230.44it/s]\n",
      "\u001b[32m2025-05-02 10:46:35.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 2 train 2.2832 test 2.2775 metric ['0.1956']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 202.42it/s]\n",
      "\u001b[32m2025-05-02 10:46:36.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 4 train 2.2716 test 2.2633 metric ['0.2052']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 245.50it/s]\n",
      "\u001b[32m2025-05-02 10:46:36.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 6 train 2.2561 test 2.2502 metric ['0.2159']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 236.49it/s]\n",
      "\u001b[32m2025-05-02 10:46:37.509\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 8 train 2.2444 test 2.2376 metric ['0.2555']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 245.19it/s]\n",
      "\u001b[32m2025-05-02 10:46:38.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 10 train 2.2280 test 2.2214 metric ['0.2791']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 246.56it/s]\n",
      "\u001b[32m2025-05-02 10:46:38.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 12 train 2.2122 test 2.2056 metric ['0.2958']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 243.48it/s]\n",
      "\u001b[32m2025-05-02 10:46:39.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 14 train 2.1988 test 2.1874 metric ['0.3372']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 225.88it/s]\n",
      "\u001b[32m2025-05-02 10:46:40.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 16 train 2.1800 test 2.1733 metric ['0.3619']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 236.43it/s]\n",
      "\u001b[32m2025-05-02 10:46:40.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 18 train 2.1619 test 2.1535 metric ['0.3923']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:07<00:00,  1.42it/s]\n",
      "\u001b[32m2025-05-02 10:46:40.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/SGD/u512_u256_e10/20250502-104640\u001b[0m\n",
      "\u001b[32m2025-05-02 10:46:40.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 262.65it/s]\n",
      "\u001b[32m2025-05-02 10:46:41.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 0 train 2.2962 test 2.2904 metric ['0.1203']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 259.37it/s]\n",
      "\u001b[32m2025-05-02 10:46:42.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 2 train 2.2836 test 2.2755 metric ['0.1450']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 263.76it/s]\n",
      "\u001b[32m2025-05-02 10:46:42.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 4 train 2.2690 test 2.2635 metric ['0.1608']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 267.02it/s]\n",
      "\u001b[32m2025-05-02 10:46:43.507\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 6 train 2.2555 test 2.2478 metric ['0.1941']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 260.06it/s]\n",
      "\u001b[32m2025-05-02 10:46:44.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 8 train 2.2393 test 2.2326 metric ['0.2288']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 258.34it/s]\n",
      "\u001b[32m2025-05-02 10:46:45.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 10 train 2.2251 test 2.2181 metric ['0.2672']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 267.57it/s]\n",
      "\u001b[32m2025-05-02 10:46:46.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 12 train 2.2090 test 2.2024 metric ['0.2975']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 264.16it/s]\n",
      "\u001b[32m2025-05-02 10:46:46.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 14 train 2.1933 test 2.1860 metric ['0.3247']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 261.58it/s]\n",
      "\u001b[32m2025-05-02 10:46:47.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 16 train 2.1762 test 2.1659 metric ['0.3683']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 261.18it/s]\n",
      "\u001b[32m2025-05-02 10:46:47.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 18 train 2.1570 test 2.1483 metric ['0.3636']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:07<00:00,  1.43it/s]\n",
      "\u001b[32m2025-05-02 10:46:47.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/SGD/u512_u128_e10/20250502-104647\u001b[0m\n",
      "\u001b[32m2025-05-02 10:46:47.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 279.42it/s]\n",
      "\u001b[32m2025-05-02 10:46:48.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 0 train 2.2996 test 2.2926 metric ['0.0975']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 278.78it/s]\n",
      "\u001b[32m2025-05-02 10:46:49.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 2 train 2.2882 test 2.2812 metric ['0.1062']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 259.81it/s]\n",
      "\u001b[32m2025-05-02 10:46:49.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 4 train 2.2751 test 2.2707 metric ['0.1542']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 279.47it/s]\n",
      "\u001b[32m2025-05-02 10:46:50.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 6 train 2.2661 test 2.2595 metric ['0.2498']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 274.35it/s]\n",
      "\u001b[32m2025-05-02 10:46:51.028\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 8 train 2.2534 test 2.2477 metric ['0.2978']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 282.25it/s]\n",
      "\u001b[32m2025-05-02 10:46:51.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 10 train 2.2417 test 2.2368 metric ['0.3372']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 272.11it/s]\n",
      "\u001b[32m2025-05-02 10:46:52.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 12 train 2.2285 test 2.2227 metric ['0.3689']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 282.23it/s]\n",
      "\u001b[32m2025-05-02 10:46:52.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 14 train 2.2167 test 2.2118 metric ['0.3798']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 271.93it/s]\n",
      "\u001b[32m2025-05-02 10:46:53.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 16 train 2.2032 test 2.1974 metric ['0.3917']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 278.68it/s]\n",
      "\u001b[32m2025-05-02 10:46:54.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 18 train 2.1920 test 2.1824 metric ['0.4070']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:06<00:00,  1.63it/s]\n",
      "\u001b[32m2025-05-02 10:46:54.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/SGD/u256_u512_e10/20250502-104654\u001b[0m\n",
      "\u001b[32m2025-05-02 10:46:54.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 293.36it/s]\n",
      "\u001b[32m2025-05-02 10:46:54.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 0 train 2.3020 test 2.2967 metric ['0.1542']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 292.24it/s]\n",
      "\u001b[32m2025-05-02 10:46:55.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 2 train 2.2913 test 2.2833 metric ['0.2003']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 296.30it/s]\n",
      "\u001b[32m2025-05-02 10:46:55.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 4 train 2.2772 test 2.2709 metric ['0.2444']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 289.30it/s]\n",
      "\u001b[32m2025-05-02 10:46:56.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 6 train 2.2633 test 2.2583 metric ['0.2800']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 294.31it/s]\n",
      "\u001b[32m2025-05-02 10:46:57.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 8 train 2.2511 test 2.2420 metric ['0.3223']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 275.83it/s]\n",
      "\u001b[32m2025-05-02 10:46:57.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 10 train 2.2373 test 2.2301 metric ['0.3225']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 281.56it/s]\n",
      "\u001b[32m2025-05-02 10:46:58.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 12 train 2.2204 test 2.2143 metric ['0.3448']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 286.56it/s]\n",
      "\u001b[32m2025-05-02 10:46:58.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 14 train 2.2056 test 2.1959 metric ['0.3744']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 292.94it/s]\n",
      "\u001b[32m2025-05-02 10:46:59.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 16 train 2.1881 test 2.1804 metric ['0.3947']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 293.51it/s]\n",
      "\u001b[32m2025-05-02 10:46:59.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 18 train 2.1705 test 2.1608 metric ['0.4278']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:05<00:00,  1.70it/s]\n",
      "\u001b[32m2025-05-02 10:47:00.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/SGD/u256_u256_e10/20250502-104700\u001b[0m\n",
      "\u001b[32m2025-05-02 10:47:00.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 312.78it/s]\n",
      "\u001b[32m2025-05-02 10:47:00.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 0 train 2.2967 test 2.2919 metric ['0.1477']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 313.87it/s]\n",
      "\u001b[32m2025-05-02 10:47:01.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 2 train 2.2859 test 2.2799 metric ['0.1970']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 316.76it/s]\n",
      "\u001b[32m2025-05-02 10:47:01.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 4 train 2.2744 test 2.2693 metric ['0.2380']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 287.76it/s]\n",
      "\u001b[32m2025-05-02 10:47:02.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 6 train 2.2631 test 2.2578 metric ['0.2889']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 311.93it/s]\n",
      "\u001b[32m2025-05-02 10:47:02.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 8 train 2.2518 test 2.2462 metric ['0.3166']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 312.08it/s]\n",
      "\u001b[32m2025-05-02 10:47:03.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 10 train 2.2415 test 2.2340 metric ['0.3530']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 314.66it/s]\n",
      "\u001b[32m2025-05-02 10:47:03.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 12 train 2.2283 test 2.2212 metric ['0.3673']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 303.16it/s]\n",
      "\u001b[32m2025-05-02 10:47:04.507\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 14 train 2.2134 test 2.2074 metric ['0.3948']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 301.53it/s]\n",
      "\u001b[32m2025-05-02 10:47:05.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 16 train 2.2023 test 2.1927 metric ['0.4108']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 311.33it/s]\n",
      "\u001b[32m2025-05-02 10:47:05.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 18 train 2.1808 test 2.1740 metric ['0.4264']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:05<00:00,  1.78it/s]\n",
      "\u001b[32m2025-05-02 10:47:05.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/SGD/u256_u128_e10/20250502-104705\u001b[0m\n",
      "\u001b[32m2025-05-02 10:47:05.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 303.50it/s]\n",
      "\u001b[32m2025-05-02 10:47:06.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 0 train 2.2982 test 2.2942 metric ['0.1837']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 305.96it/s]\n",
      "\u001b[32m2025-05-02 10:47:06.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 2 train 2.2895 test 2.2855 metric ['0.2125']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 320.51it/s]\n",
      "\u001b[32m2025-05-02 10:47:07.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 4 train 2.2797 test 2.2751 metric ['0.2316']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 317.46it/s]\n",
      "\u001b[32m2025-05-02 10:47:07.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 6 train 2.2720 test 2.2672 metric ['0.2520']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 321.92it/s]\n",
      "\u001b[32m2025-05-02 10:47:08.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 8 train 2.2624 test 2.2582 metric ['0.2816']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 325.03it/s]\n",
      "\u001b[32m2025-05-02 10:47:08.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 10 train 2.2521 test 2.2474 metric ['0.3145']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 304.15it/s]\n",
      "\u001b[32m2025-05-02 10:47:09.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 12 train 2.2416 test 2.2381 metric ['0.3317']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 304.79it/s]\n",
      "\u001b[32m2025-05-02 10:47:10.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 14 train 2.2342 test 2.2273 metric ['0.3613']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 318.12it/s]\n",
      "\u001b[32m2025-05-02 10:47:10.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 16 train 2.2199 test 2.2136 metric ['0.3845']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 315.10it/s]\n",
      "\u001b[32m2025-05-02 10:47:11.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 18 train 2.2098 test 2.2039 metric ['0.4025']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:05<00:00,  1.80it/s]\n",
      "\u001b[32m2025-05-02 10:47:11.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/SGD/u128_u512_e10/20250502-104711\u001b[0m\n",
      "\u001b[32m2025-05-02 10:47:11.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 320.87it/s]\n",
      "\u001b[32m2025-05-02 10:47:11.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 0 train 2.2987 test 2.2932 metric ['0.1100']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 324.88it/s]\n",
      "\u001b[32m2025-05-02 10:47:12.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 2 train 2.2859 test 2.2814 metric ['0.1216']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 312.81it/s]\n",
      "\u001b[32m2025-05-02 10:47:12.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 4 train 2.2755 test 2.2687 metric ['0.1439']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 325.42it/s]\n",
      "\u001b[32m2025-05-02 10:47:13.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 6 train 2.2623 test 2.2564 metric ['0.1564']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 330.21it/s]\n",
      "\u001b[32m2025-05-02 10:47:13.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 8 train 2.2507 test 2.2443 metric ['0.1667']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 316.00it/s]\n",
      "\u001b[32m2025-05-02 10:47:14.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 10 train 2.2368 test 2.2304 metric ['0.1692']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 326.55it/s]\n",
      "\u001b[32m2025-05-02 10:47:15.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 12 train 2.2236 test 2.2161 metric ['0.1780']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 314.12it/s]\n",
      "\u001b[32m2025-05-02 10:47:15.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 14 train 2.2090 test 2.2014 metric ['0.1969']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 329.70it/s]\n",
      "\u001b[32m2025-05-02 10:47:16.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 16 train 2.1929 test 2.1825 metric ['0.2263']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 327.33it/s]\n",
      "\u001b[32m2025-05-02 10:47:16.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 18 train 2.1766 test 2.1654 metric ['0.3030']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:05<00:00,  1.84it/s]\n",
      "\u001b[32m2025-05-02 10:47:16.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/SGD/u128_u256_e10/20250502-104716\u001b[0m\n",
      "\u001b[32m2025-05-02 10:47:16.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 339.12it/s]\n",
      "\u001b[32m2025-05-02 10:47:17.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 0 train 2.2949 test 2.2919 metric ['0.1817']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 338.36it/s]\n",
      "\u001b[32m2025-05-02 10:47:17.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 2 train 2.2887 test 2.2842 metric ['0.2214']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 314.16it/s]\n",
      "\u001b[32m2025-05-02 10:47:18.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 4 train 2.2789 test 2.2763 metric ['0.2712']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 332.51it/s]\n",
      "\u001b[32m2025-05-02 10:47:18.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 6 train 2.2711 test 2.2678 metric ['0.3108']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 318.32it/s]\n",
      "\u001b[32m2025-05-02 10:47:19.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 8 train 2.2623 test 2.2573 metric ['0.3391']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 339.39it/s]\n",
      "\u001b[32m2025-05-02 10:47:19.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 10 train 2.2521 test 2.2470 metric ['0.3552']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 336.82it/s]\n",
      "\u001b[32m2025-05-02 10:47:20.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 12 train 2.2436 test 2.2394 metric ['0.3484']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 338.89it/s]\n",
      "\u001b[32m2025-05-02 10:47:20.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 14 train 2.2336 test 2.2263 metric ['0.3588']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 328.71it/s]\n",
      "\u001b[32m2025-05-02 10:47:21.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 16 train 2.2201 test 2.2134 metric ['0.3750']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 340.59it/s]\n",
      "\u001b[32m2025-05-02 10:47:21.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 18 train 2.2070 test 2.1995 metric ['0.3816']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:05<00:00,  1.87it/s]\n",
      "\u001b[32m2025-05-02 10:47:21.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/SGD/u128_u128_e10/20250502-104721\u001b[0m\n",
      "\u001b[32m2025-05-02 10:47:21.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 338.71it/s]\n",
      "\u001b[32m2025-05-02 10:47:22.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 0 train 2.2968 test 2.2925 metric ['0.1169']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 322.13it/s]\n",
      "\u001b[32m2025-05-02 10:47:23.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 2 train 2.2894 test 2.2865 metric ['0.1352']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 308.89it/s]\n",
      "\u001b[32m2025-05-02 10:47:23.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 4 train 2.2809 test 2.2741 metric ['0.2117']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 333.38it/s]\n",
      "\u001b[32m2025-05-02 10:47:24.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 6 train 2.2720 test 2.2673 metric ['0.2614']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 348.59it/s]\n",
      "\u001b[32m2025-05-02 10:47:24.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 8 train 2.2638 test 2.2582 metric ['0.3289']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 333.59it/s]\n",
      "\u001b[32m2025-05-02 10:47:25.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 10 train 2.2546 test 2.2495 metric ['0.3661']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 341.03it/s]\n",
      "\u001b[32m2025-05-02 10:47:25.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 12 train 2.2429 test 2.2385 metric ['0.3987']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 346.37it/s]\n",
      "\u001b[32m2025-05-02 10:47:26.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 14 train 2.2317 test 2.2271 metric ['0.4069']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 348.16it/s]\n",
      "\u001b[32m2025-05-02 10:47:26.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 16 train 2.2229 test 2.2150 metric ['0.4248']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 326.36it/s]\n",
      "\u001b[32m2025-05-02 10:47:27.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 18 train 2.2101 test 2.2029 metric ['0.4330']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:05<00:00,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "units = [512, 256, 128]\n",
    "epochs = 10\n",
    "results = []\n",
    "\n",
    "for units1 in units:\n",
    "    for units2 in units:\n",
    "\n",
    "        settings = TrainerSettings(\n",
    "            epochs=epochs,\n",
    "            metrics=[accuracy],\n",
    "            logdir=\"modellogs\",\n",
    "            train_steps=100,\n",
    "            valid_steps=100,\n",
    "            reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML]\n",
    "        )\n",
    "\n",
    "        model = NeuralNetwork (num_classes=10, units1=units1, units2=units2)\n",
    "        settings.logdir = f\"modellogs/SGD/u{units1}_u{units2}_e{epochs}\"\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            settings=settings,\n",
    "            loss_fn=loss_func,\n",
    "            optimizer=optim.SGD,\n",
    "            traindataloader=trainstreamer,\n",
    "            validdataloader=validstreamer,\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "        )\n",
    "\n",
    "        trainer.loop()\n",
    "\n",
    "        results.append({\n",
    "            \"units1\": units1,\n",
    "            \"units2\": units2,\n",
    "            \"run_dir\": settings.logdir,\n",
    "            \"epoch\": epochs,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c702f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-02 11:37:34.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/DEEP/u512_u256_u128_e20/20250502-113734\u001b[0m\n",
      "\u001b[32m2025-05-02 11:37:34.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 175.84it/s]\n",
      "\u001b[32m2025-05-02 11:37:35.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 0 train 0.9566 test 0.6424 metric ['0.7641']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 186.47it/s]\n",
      "\u001b[32m2025-05-02 11:37:36.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 2 train 0.5678 test 0.5520 metric ['0.8002']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 181.61it/s]\n",
      "\u001b[32m2025-05-02 11:37:37.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 4 train 0.5071 test 0.5045 metric ['0.8145']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 188.86it/s]\n",
      "\u001b[32m2025-05-02 11:37:37.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 6 train 0.5061 test 0.5440 metric ['0.8063']\u001b[0m\n",
      "\u001b[32m2025-05-02 11:37:37.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.5045, current loss 0.5440.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 187.16it/s]\n",
      "\u001b[32m2025-05-02 11:37:38.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 8 train 0.4709 test 0.4518 metric ['0.8350']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 186.22it/s]\n",
      "\u001b[32m2025-05-02 11:37:39.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 10 train 0.4253 test 0.4616 metric ['0.8363']\u001b[0m\n",
      "\u001b[32m2025-05-02 11:37:39.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4518, current loss 0.4616.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 179.72it/s]\n",
      "\u001b[32m2025-05-02 11:37:40.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 12 train 0.4163 test 0.5123 metric ['0.8127']\u001b[0m\n",
      "\u001b[32m2025-05-02 11:37:40.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4518, current loss 0.5123.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 184.45it/s]\n",
      "\u001b[32m2025-05-02 11:37:41.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 14 train 0.4134 test 0.4412 metric ['0.8372']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 180.66it/s]\n",
      "\u001b[32m2025-05-02 11:37:42.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 16 train 0.3949 test 0.4091 metric ['0.8519']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 185.31it/s]\n",
      "\u001b[32m2025-05-02 11:37:42.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 18 train 0.3989 test 0.4093 metric ['0.8580']\u001b[0m\n",
      "\u001b[32m2025-05-02 11:37:42.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4091, current loss 0.4093.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 177.40it/s]\n",
      "\u001b[32m2025-05-02 11:37:43.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 20 train 0.3778 test 0.4210 metric ['0.8461']\u001b[0m\n",
      "\u001b[32m2025-05-02 11:37:43.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.4091, current loss 0.4210.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 181.22it/s]\n",
      "\u001b[32m2025-05-02 11:37:44.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 22 train 0.4014 test 0.4082 metric ['0.8536']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 166.98it/s]\n",
      "\u001b[32m2025-05-02 11:37:45.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 24 train 0.3812 test 0.3788 metric ['0.8642']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 150.49it/s]\n",
      "\u001b[32m2025-05-02 11:37:46.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 26 train 0.3757 test 0.4086 metric ['0.8458']\u001b[0m\n",
      "\u001b[32m2025-05-02 11:37:46.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.3788, current loss 0.4086.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 144.53it/s]\n",
      "\u001b[32m2025-05-02 11:37:47.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 28 train 0.3554 test 0.4057 metric ['0.8583']\u001b[0m\n",
      "\u001b[32m2025-05-02 11:37:47.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.3788, current loss 0.4057.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 131.79it/s]\n",
      "\u001b[32m2025-05-02 11:37:48.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 30 train 0.3562 test 0.4133 metric ['0.8516']\u001b[0m\n",
      "\u001b[32m2025-05-02 11:37:48.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.3788, current loss 0.4133.Counter 3/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 122.17it/s]\n",
      "\u001b[32m2025-05-02 11:37:49.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 32 train 0.3435 test 0.4157 metric ['0.8509']\u001b[0m\n",
      "\u001b[32m2025-05-02 11:37:49.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.3788, current loss 0.4157.Counter 4/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 117.82it/s]\n",
      "\u001b[32m2025-05-02 11:37:50.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 34 train 0.3441 test 0.3840 metric ['0.8627']\u001b[0m\n",
      "\u001b[32m2025-05-02 11:37:50.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.3788, current loss 0.3840.Counter 5/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 116.49it/s]\n",
      "\u001b[32m2025-05-02 11:37:52.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 36 train 0.3536 test 0.4016 metric ['0.8592']\u001b[0m\n",
      "\u001b[32m2025-05-02 11:37:52.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mbest loss: 0.3788, current loss 0.4016.Counter 6/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 116.78it/s]\n",
      "\u001b[32m2025-05-02 11:37:53.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mEpoch 38 train 0.3548 test 0.3633 metric ['0.8678']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 20/20 [00:18<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "units1 = 512\n",
    "units2 = 256\n",
    "units3 = 128\n",
    "epochs = 20\n",
    "\n",
    "settings = TrainerSettings(\n",
    "            epochs=epochs,\n",
    "            metrics=[accuracy],\n",
    "            logdir=\"modellogs\",\n",
    "            train_steps=100,\n",
    "            valid_steps=100,\n",
    "            reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML]\n",
    "        )\n",
    "\n",
    "model = DeepNeuralNetwork (num_classes=10, units1=units1, units2=units2, units3 = units3)\n",
    "settings.logdir = f\"modellogs/DEEP/u{units1}_u{units2}_u{units3}_e{epochs}\"\n",
    "        \n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_func,\n",
    "    optimizer=optim.Adam,\n",
    "    traindataloader=trainstreamer,\n",
    "    validdataloader=validstreamer,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    ")\n",
    "\n",
    "trainer.loop()\n",
    "\n",
    "resultsdeep = []\n",
    "\n",
    "resultsdeep.append({\n",
    "    \"units1\": units1,\n",
    "    \"units2\": units2,\n",
    "    \"run_dir\": settings.logdir,\n",
    "    \"epoch\": epochs,\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
