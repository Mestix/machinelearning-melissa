{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "sys.path.append(os.path.abspath('../models'))\n",
    "sys.path.append(os.path.abspath('../dev'))\n",
    "\n",
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "from mltrainer import Trainer, TrainerSettings, ReportTypes, metrics\n",
    "from neural_network import NeuralNetwork\n",
    "from neural_network import DeepNeuralNetwork\n",
    "\n",
    "from helpers import get_last_accuracy_from_tensorboard\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashionfactory = DatasetFactoryProvider.create_factory(DatasetType.FASHION)\n",
    "preprocessor = BasePreprocessor()\n",
    "\n",
    "batchsize = 64\n",
    "\n",
    "streamers = fashionfactory.create_datastreamer(batchsize=batchsize, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]\n",
    "\n",
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()\n",
    "\n",
    "accuracy = metrics.Accuracy()\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "units = [2048, 1024, 512, 256, 128, 64, 32, 16]\n",
    "\n",
    "epochs = 5\n",
    "accuracies5 = []\n",
    "dir = \"modellogs/UNITS/EPOCH5/\"\n",
    "\n",
    "for units1 in units:\n",
    "    row = []\n",
    "    for units2 in units:\n",
    "        logdir = f\"{dir}u{units1}_u{units2}_e{epochs}\"\n",
    "\n",
    "        settings = TrainerSettings(\n",
    "            epochs=epochs,\n",
    "            metrics=[accuracy],\n",
    "            logdir=\"modellogs\",\n",
    "            train_steps=100,\n",
    "            valid_steps=100,\n",
    "            reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML]\n",
    "        )\n",
    "\n",
    "        model = NeuralNetwork(num_classes=10, units1=units1, units2=units2)\n",
    "        settings.logdir = f\"{dir}u{units1}_u{units2}_e{epochs}\"\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            settings=settings,\n",
    "            loss_fn=loss_func,\n",
    "            optimizer=optim.Adam,\n",
    "            traindataloader=trainstreamer,\n",
    "            validdataloader=validstreamer,\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "        )\n",
    "\n",
    "        trainer.loop()\n",
    "        \n",
    "        tb_subdirs = [os.path.join(logdir, d) for d in os.listdir(logdir) if os.path.isdir(os.path.join(logdir, d))]\n",
    "\n",
    "        # Zoek eerste subdir met tensorboard events\n",
    "        tb_dir = next((d for d in tb_subdirs if any(\"events.out.tfevents\" in f for f in os.listdir(d))), None)\n",
    "\n",
    "        if tb_dir:\n",
    "            last_acc = get_last_accuracy_from_tensorboard(tb_dir)\n",
    "        else:\n",
    "            last_acc = np.nan\n",
    "        \n",
    "        row.append(last_acc)\n",
    "    accuracies5.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot de heatmap\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.heatmap(\n",
    "    accuracies5,\n",
    "    annot=True,\n",
    "    fmt=\".1f\",\n",
    "    xticklabels=units,\n",
    "    yticklabels=units,\n",
    "    cmap=\"YlOrRd\",\n",
    "    cbar_kws={'label': 'Accuracy (%)'}\n",
    ")\n",
    "ax.set_xlabel(\"units2\")\n",
    "ax.set_ylabel(\"units1\")\n",
    "ax.set_title(\"Laatste Accuracy per Units-Combinatie epochs = 5\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"heatmap_epochs5\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "units = [2048, 1024, 512, 256, 128, 64, 32, 16]\n",
    "\n",
    "epochs = 10\n",
    "accuracies = []\n",
    "dir = \"modellogs/UNITS/EPOCH10/\"\n",
    "\n",
    "for units1 in units:\n",
    "    row = []\n",
    "    for units2 in units:\n",
    "        logdir = f\"{dir}u{units1}_u{units2}_e{epochs}\"\n",
    "\n",
    "        settings = TrainerSettings(\n",
    "            epochs=epochs,\n",
    "            metrics=[accuracy],\n",
    "            logdir=\"modellogs\",\n",
    "            train_steps=100,\n",
    "            valid_steps=100,\n",
    "            reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML]\n",
    "        )\n",
    "\n",
    "        model = NeuralNetwork(num_classes=10, units1=units1, units2=units2)\n",
    "        settings.logdir = f\"{dir}u{units1}_u{units2}_e{epochs}\"\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            settings=settings,\n",
    "            loss_fn=loss_func,\n",
    "            optimizer=optim.Adam,\n",
    "            traindataloader=trainstreamer,\n",
    "            validdataloader=validstreamer,\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "        )\n",
    "\n",
    "        trainer.loop()\n",
    "        \n",
    "        tb_subdirs = [os.path.join(logdir, d) for d in os.listdir(logdir) if os.path.isdir(os.path.join(logdir, d))]\n",
    "\n",
    "        # Zoek eerste subdir met tensorboard events\n",
    "        tb_dir = next((d for d in tb_subdirs if any(\"events.out.tfevents\" in f for f in os.listdir(d))), None)\n",
    "\n",
    "        if tb_dir:\n",
    "            last_acc = get_last_accuracy_from_tensorboard(tb_dir)\n",
    "        else:\n",
    "            last_acc = np.nan\n",
    "        \n",
    "        row.append(last_acc)\n",
    "    accuracies.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot de heatmap\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.heatmap(\n",
    "    accuracies,\n",
    "    annot=True,\n",
    "    fmt=\".1f\",\n",
    "    xticklabels=units,\n",
    "    yticklabels=units,\n",
    "    cmap=\"YlOrRd\",\n",
    "    cbar_kws={'label': 'Accuracy (%)'}\n",
    ")\n",
    "ax.set_xlabel(\"units2\")\n",
    "ax.set_ylabel(\"units1\")\n",
    "ax.set_title(\"Laatste Accuracy per Units-Combinatie epochs = 10\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"heatmap_epochs10\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "units = [512, 256, 128]\n",
    "epochs = 10\n",
    "results = []\n",
    "\n",
    "for units1 in units:\n",
    "    for units2 in units:\n",
    "\n",
    "        settings = TrainerSettings(\n",
    "            epochs=epochs,\n",
    "            metrics=[accuracy],\n",
    "            logdir=\"modellogs\",\n",
    "            train_steps=100,\n",
    "            valid_steps=100,\n",
    "            reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML]\n",
    "        )\n",
    "\n",
    "        model = NeuralNetwork (num_classes=10, units1=units1, units2=units2)\n",
    "        settings.logdir = f\"modellogs/SGD/u{units1}_u{units2}_e{epochs}\"\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            settings=settings,\n",
    "            loss_fn=loss_func,\n",
    "            optimizer=optim.SGD,\n",
    "            traindataloader=trainstreamer,\n",
    "            validdataloader=validstreamer,\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "        )\n",
    "\n",
    "        trainer.loop()\n",
    "\n",
    "        results.append({\n",
    "            \"units1\": units1,\n",
    "            \"units2\": units2,\n",
    "            \"run_dir\": settings.logdir,\n",
    "            \"epoch\": epochs,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "units1 = 512\n",
    "units2 = 256\n",
    "units3 = 128\n",
    "epochs = 20\n",
    "\n",
    "settings = TrainerSettings(\n",
    "            epochs=epochs,\n",
    "            metrics=[accuracy],\n",
    "            logdir=\"modellogs\",\n",
    "            train_steps=100,\n",
    "            valid_steps=100,\n",
    "            reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML]\n",
    "        )\n",
    "\n",
    "model = DeepNeuralNetwork (num_classes=10, units1=units1, units2=units2, units3 = units3)\n",
    "settings.logdir = f\"modellogs/DEEP/u{units1}_u{units2}_u{units3}_e{epochs}\"\n",
    "        \n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_func,\n",
    "    optimizer=optim.Adam,\n",
    "    traindataloader=trainstreamer,\n",
    "    validdataloader=validstreamer,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    ")\n",
    "\n",
    "trainer.loop()\n",
    "\n",
    "resultsdeep = []\n",
    "\n",
    "resultsdeep.append({\n",
    "    \"units1\": units1,\n",
    "    \"units2\": units2,\n",
    "    \"run_dir\": settings.logdir,\n",
    "    \"epoch\": epochs,\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
